{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5ccd14",
   "metadata": {},
   "source": [
    "# Explainable AI for Lung Cancer Classification\n",
    "## Complete Pipeline Demo\n",
    "\n",
    "This notebook demonstrates the complete end-to-end pipeline:\n",
    "1. Load a CT scan image\n",
    "2. Run classification using ResNet-50\n",
    "3. Generate Grad-CAM heatmap\n",
    "4. Generate RAG-based explanation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0474563c",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8165cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Standard imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Project imports\n",
    "from src.utils.config import Config\n",
    "from src.utils.helpers import set_seed, get_device\n",
    "from src.pipeline import ExplainablePipeline, create_demo_visualization\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Get device\n",
    "device = get_device()\n",
    "\n",
    "# Load configuration\n",
    "config = Config()\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb291bb",
   "metadata": {},
   "source": [
    "## 2. Initialize the Pipeline\n",
    "\n",
    "The `ExplainablePipeline` class combines:\n",
    "- ResNet-50 classifier\n",
    "- Grad-CAM visualization\n",
    "- RAG-based explanation generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a00e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the explainable pipeline\n",
    "# If you have a trained model, provide the checkpoint path\n",
    "checkpoint_path = os.path.join(config.checkpoint_dir, \"best_model.pth\")\n",
    "\n",
    "pipeline = ExplainablePipeline(\n",
    "    checkpoint_path=checkpoint_path if os.path.exists(checkpoint_path) else None,\n",
    "    config=config,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0842def2",
   "metadata": {},
   "source": [
    "## 3. Find a Sample Image\n",
    "\n",
    "Let's find a CT scan image from the dataset to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sample images from the dataset\n",
    "sample_images = {}\n",
    "\n",
    "for class_name in config.class_names:\n",
    "    class_dir = Path(config.dataset_dir) / class_name\n",
    "    if class_dir.exists():\n",
    "        images = list(class_dir.glob(\"*.png\")) + \\\n",
    "                list(class_dir.glob(\"*.jpg\")) + \\\n",
    "                list(class_dir.glob(\"*.jpeg\"))\n",
    "        if images:\n",
    "            sample_images[class_name] = images[:3]  # Get up to 3 samples per class\n",
    "            print(f\"{class_name}: {len(images)} images found\")\n",
    "\n",
    "if not sample_images:\n",
    "    print(\"\\n⚠️ No images found in dataset folder.\")\n",
    "    print(\"Please add images to the dataset/ subfolders.\")\n",
    "else:\n",
    "    print(f\"\\n✓ Found images in {len(sample_images)} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9640a8e8",
   "metadata": {},
   "source": [
    "## 4. Run Prediction on a Sample Image\n",
    "\n",
    "Select an image and run the complete pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample image (change this to analyze different images)\n",
    "if sample_images:\n",
    "    # Get first available image\n",
    "    first_class = list(sample_images.keys())[0]\n",
    "    image_path = str(sample_images[first_class][0])\n",
    "    print(f\"Selected image: {image_path}\")\n",
    "    print(f\"True class: {first_class}\")\n",
    "else:\n",
    "    # If no images, you can manually set a path\n",
    "    image_path = None\n",
    "    print(\"Set image_path manually to an image file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction\n",
    "if image_path and os.path.exists(image_path):\n",
    "    result = pipeline.predict(image_path)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"PREDICTION RESULT\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Predicted Class: {result.predicted_class.replace('_', ' ').title()}\")\n",
    "    print(f\"Confidence: {result.confidence * 100:.2f}%\")\n",
    "    print(\"\\nAll Probabilities:\")\n",
    "    for cls, prob in sorted(result.all_probabilities.items(), key=lambda x: -x[1]):\n",
    "        print(f\"  {cls:25s}: {prob*100:5.1f}%\")\n",
    "else:\n",
    "    print(\"No image to process. Please add images to the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d2a89e",
   "metadata": {},
   "source": [
    "## 5. Visualize Grad-CAM Heatmap\n",
    "\n",
    "The Grad-CAM heatmap shows which regions the model focused on to make its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec18bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'result' in dir():\n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(result.original_image)\n",
    "    axes[0].set_title('Original CT Image', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Heatmap\n",
    "    im = axes[1].imshow(result.heatmap, cmap='jet', vmin=0, vmax=1)\n",
    "    axes[1].set_title('Grad-CAM Heatmap', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    plt.colorbar(im, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Overlay\n",
    "    axes[2].imshow(result.overlay)\n",
    "    axes[2].set_title('Overlay', fontsize=12)\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Prediction: {result.predicted_class.replace(\"_\", \" \").title()} ({result.confidence*100:.1f}%)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run prediction first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3bf9c3",
   "metadata": {},
   "source": [
    "## 6. RAG-Based Explanation\n",
    "\n",
    "The explanation combines:\n",
    "- **Visual Evidence**: What the model focused on (from Grad-CAM)\n",
    "- **Medical Context**: Relevant medical knowledge (from knowledge base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79edf4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'result' in dir():\n",
    "    # Print the full explanation\n",
    "    result.print_explanation()\n",
    "else:\n",
    "    print(\"Run prediction first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7129b1fb",
   "metadata": {},
   "source": [
    "## 7. Comprehensive Demo Visualization\n",
    "\n",
    "Create a single figure with all information combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b85daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'result' in dir():\n",
    "    # Create comprehensive visualization\n",
    "    fig = create_demo_visualization(\n",
    "        result,\n",
    "        save_path=os.path.join(config.results_dir, \"notebook_demo.png\")\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run prediction first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e131ca3",
   "metadata": {},
   "source": [
    "## 8. Batch Processing (Multiple Images)\n",
    "\n",
    "Process multiple images at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e197af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all sample images\n",
    "all_images = []\n",
    "for class_name, images in sample_images.items():\n",
    "    all_images.extend([str(img) for img in images[:2]])  # 2 per class\n",
    "\n",
    "print(f\"Processing {len(all_images)} images...\")\n",
    "\n",
    "if all_images:\n",
    "    results = pipeline.predict_batch(all_images[:8])  # Limit to 8 for demo\n",
    "    \n",
    "    # Create summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BATCH RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    for r in results:\n",
    "        print(f\"{Path(r.image_path).name:30s} → {r.predicted_class:25s} ({r.confidence*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"No images to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1854241",
   "metadata": {},
   "source": [
    "## 9. Explore the Knowledge Base\n",
    "\n",
    "See what medical knowledge is available for each cancer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rag.knowledge_base import MedicalKnowledgeBase\n",
    "\n",
    "kb = MedicalKnowledgeBase()\n",
    "\n",
    "# Show knowledge for each class\n",
    "for class_name in config.class_names:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"KNOWLEDGE: {class_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    entries = kb.get_class_knowledge(class_name)\n",
    "    for entry in entries[:2]:  # Show first 2 entries\n",
    "        print(f\"\\n• {entry['content'][:200]}...\")\n",
    "        print(f\"  Source: {entry['source']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79359589",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete **Explainable AI for Lung Cancer Classification** pipeline:\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|--------|\n",
    "| ResNet-50 | Classification of CT images into 4 classes |\n",
    "| Grad-CAM | Visual explanation of model attention |\n",
    "| XAI→Text | Converts visual attention to textual description |\n",
    "| Knowledge Base | Stores curated medical facts |\n",
    "| RAG Pipeline | Retrieves relevant knowledge for explanation |\n",
    "\n",
    "### Key Points for Viva:\n",
    "1. **Transfer Learning**: Uses ImageNet weights for better generalization\n",
    "2. **Explainability**: Grad-CAM shows WHERE, RAG explains WHY\n",
    "3. **Novel Contribution**: Bridging visual XAI to textual explanations\n",
    "4. **Citable**: All medical knowledge has sources"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
