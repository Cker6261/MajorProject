# Explainable AI for Lung Cancer Classification
## Project Pseudocode & Algorithm

---

## ğŸ¯ Main Pipeline Algorithm

```
ALGORITHM: ExplainableLungCancerClassification

INPUT:  CT scan image (chest X-ray or CT slice)
OUTPUT: Prediction with visual and textual explanation

FUNCTION lung_cancer_pipeline(input_image):
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PHASE 1: IMAGE PREPROCESSING
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    image â† load_image(input_image)
    image â† resize(image, size=224Ã—224)
    image â† normalize(image, mean=[0.485, 0.456, 0.406], 
                              std=[0.229, 0.224, 0.225])
    tensor â† convert_to_tensor(image)
    
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PHASE 2: MODEL PREDICTION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    logits â† ResNet50_Model(tensor)
    probabilities â† softmax(logits)
    prediction â† argmax(probabilities)
    confidence â† max(probabilities)
    
    class_name â† CLASS_NAMES[prediction]
    # CLASS_NAMES = [adenocarcinoma, benign, large_cell, normal, squamous]
    
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PHASE 3: GRAD-CAM VISUALIZATION (XAI)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Get activations from last convolutional layer
    activations â† forward_hook(model.layer4, tensor)
    
    # Compute gradients via backpropagation
    target_score â† logits[prediction]
    gradients â† backward(target_score)
    
    # Compute importance weights (Global Average Pooling)
    weights â† global_average_pool(gradients)
    
    # Generate weighted activation map
    heatmap â† ReLU(Î£ weights Ã— activations)
    heatmap â† normalize(heatmap, range=[0, 1])
    heatmap â† resize(heatmap, size=224Ã—224)
    
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PHASE 4: HEATMAP ANALYSIS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Analyze spatial distribution
    attention_regions â† find_high_attention_regions(heatmap, threshold=0.5)
    spatial_location â† classify_location(attention_regions)
    # locations: upper_left, upper_right, lower_left, lower_right, central
    
    # Analyze intensity
    intensity_score â† mean(heatmap[attention_regions])
    coverage â† count(heatmap > 0.5) / total_pixels
    
    # Generate visual description
    visual_cues â† {
        "location": spatial_location,
        "intensity": intensity_score,
        "coverage": coverage,
        "pattern": detect_pattern(attention_regions)
    }
    
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PHASE 5: RAG-BASED KNOWLEDGE RETRIEVAL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Generate search keywords
    keywords â† extract_keywords(class_name, visual_cues)
    # Example: ["adenocarcinoma", "peripheral", "ground glass"]
    
    # Retrieve relevant medical knowledge
    knowledge_entries â† []
    FOR each keyword IN keywords:
        matches â† search_knowledge_base(keyword)
        knowledge_entries.append(matches)
    
    # Rank by relevance
    ranked_entries â† rank_by_relevance(knowledge_entries, keywords)
    top_knowledge â† select_top_k(ranked_entries, k=3)
    
    # Compile medical context
    medical_context â† concatenate(top_knowledge)
    sources â† extract_citations(top_knowledge)
    
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PHASE 6: EXPLANATION GENERATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    explanation â† format_explanation(
        prediction = class_name,
        confidence = confidence,
        visual_evidence = describe(visual_cues),
        medical_context = medical_context,
        sources = sources
    )
    
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # OUTPUT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    output â† {
        "prediction": class_name,
        "confidence": confidence,
        "probabilities": probabilities,
        "heatmap": heatmap,
        "overlay": blend(image, heatmap),
        "explanation": explanation
    }
    
    RETURN output

END FUNCTION
```

---

## ğŸ“Š Component Algorithms

### 1. ResNet-50 with Transfer Learning

```
ALGORITHM: TransferLearning_ResNet50

# Load pretrained model (ImageNet weights)
base_model â† load_pretrained("ResNet-50", weights="ImageNet")

# Modify classifier head
original_fc â† base_model.fc  # 2048 â†’ 1000 (ImageNet classes)
new_fc â† Sequential(
    Dropout(p=0.5),
    Linear(2048 â†’ 5)  # 5 lung cancer classes
)
base_model.fc â† new_fc

# Training
FOR each epoch IN [1, ..., num_epochs]:
    FOR each batch IN training_data:
        outputs â† base_model(batch.images)
        loss â† CrossEntropyLoss(outputs, batch.labels)
        loss.backward()
        optimizer.step()
    
    val_accuracy â† evaluate(base_model, validation_data)
    IF val_accuracy > best_accuracy:
        save_checkpoint(base_model)
```

### 2. Grad-CAM Algorithm

```
ALGORITHM: GradCAM

INPUT:  model, input_image, target_class
OUTPUT: heatmap (same size as input)

# Step 1: Forward pass with hook
activations â† []
REGISTER forward_hook ON model.layer4:
    activations â† output

output â† model(input_image)

# Step 2: Backward pass
model.zero_grad()
target_score â† output[0, target_class]
target_score.backward()

gradients â† get_gradients(model.layer4)

# Step 3: Compute weights via GAP
weights â† mean(gradients, dim=[height, width])  # Shape: [channels]

# Step 4: Weighted combination
cam â† Î£(weights[c] Ã— activations[c]) for c in channels

# Step 5: Apply ReLU (keep positive influences only)
cam â† ReLU(cam)

# Step 6: Normalize and resize
cam â† (cam - min(cam)) / (max(cam) - min(cam))
heatmap â† resize(cam, size=input_image.size)

RETURN heatmap
```

### 3. RAG Knowledge Retrieval

```
ALGORITHM: RAG_Retrieval

INPUT:  predicted_class, visual_cues
OUTPUT: medical_context, sources

# Knowledge Base Structure
KNOWLEDGE_BASE â† [
    {id: "adeno_001", 
     keywords: ["adenocarcinoma", "peripheral"],
     content: "Adenocarcinoma typically presents...",
     source: "WHO Classification 2021"},
    ...
]

# Step 1: Generate query keywords
keywords â† []
keywords.add(predicted_class)
keywords.add(visual_cues.location_keywords)
keywords.add(visual_cues.pattern_keywords)

# Step 2: Search knowledge base
results â† []
FOR each entry IN KNOWLEDGE_BASE:
    score â† 0
    FOR each keyword IN keywords:
        IF keyword IN entry.keywords:
            score â† score + 1
    IF score > 0:
        results.add((entry, score))

# Step 3: Rank and select
results â† sort(results, by=score, descending=True)
top_results â† results[0:3]

# Step 4: Format output
medical_context â† concatenate([r.content for r in top_results])
sources â† [r.source for r in top_results]

RETURN medical_context, sources
```

---

## ğŸ”„ Data Flow Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CT Scan       â”‚
â”‚   (Input)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Preprocessing  â”‚  â†’ Resize to 224Ã—224
â”‚                 â”‚  â†’ Normalize (ImageNet stats)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ResNet-50     â”‚  â†’ 23.5M parameters
â”‚   (Backbone)    â”‚  â†’ Pretrained on ImageNet
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Predictâ”‚ â”‚  Grad-CAM â”‚
â”‚Class  â”‚ â”‚  Heatmap  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚           â”‚
    â”‚     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚     â”‚  Analyze  â”‚
    â”‚     â”‚  Regions  â”‚
    â”‚     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚           â”‚
    â”‚     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚     â”‚    RAG    â”‚â—„â”€â”€ Knowledge Base
    â”‚     â”‚ Retrieval â”‚    (19 entries)
    â”‚     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”‚           â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   EXPLAINABLE   â”‚
â”‚     OUTPUT      â”‚
â”‚                 â”‚
â”‚ â€¢ Prediction    â”‚
â”‚ â€¢ Confidence    â”‚
â”‚ â€¢ Heatmap       â”‚
â”‚ â€¢ Explanation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Class Definitions

| Class ID | Class Name              | Description                    |
|----------|------------------------|--------------------------------|
| 0        | Adenocarcinoma         | Most common lung cancer type   |
| 1        | Benign Cases           | Non-cancerous conditions       |
| 2        | Large Cell Carcinoma   | Aggressive cancer type         |
| 3        | Normal Cases           | Healthy lung tissue            |
| 4        | Squamous Cell Carcinoma| Central lung cancer            |

---

## ğŸ› ï¸ Technical Specifications

| Component          | Specification                          |
|--------------------|----------------------------------------|
| Model Architecture | ResNet-50 (Modified)                   |
| Input Size         | 224 Ã— 224 Ã— 3                         |
| Parameters         | 23,518,277                             |
| XAI Method         | Grad-CAM (layer4)                      |
| Knowledge Base     | 19 curated medical entries             |
| Framework          | PyTorch 2.5.1 + CUDA 12.1             |
| GPU                | NVIDIA RTX 3060 (6GB VRAM)            |

---

## ğŸ“š References

1. He, K., et al. (2016). "Deep Residual Learning for Image Recognition." CVPR.
2. Selvaraju, R.R., et al. (2017). "Grad-CAM: Visual Explanations from Deep Networks." ICCV.
3. Travis, W.D., et al. (2021). "WHO Classification of Tumours of the Lung."
4. Lewis, P., et al. (2020). "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks."

---

*Document prepared for Major Project Review*
*December 2025*
