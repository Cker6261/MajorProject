# Explainable AI for Multi-Class Lung Cancer Classification

## Using Deep Learning and RAG-Based Knowledge Retrieval

---

## ğŸ¯ Project Overview

This project implements an **explainable AI system** for classifying lung CT images into four categories:
- **Adenocarcinoma** - Most common type of lung cancer
- **Squamous Cell Carcinoma** - Often found in central lung areas
- **Large Cell Carcinoma** - Fast-growing cancer type
- **Normal/Benign** - Healthy lung tissue

### What Makes This Project Unique?

Traditional medical AI systems provide predictions but lack interpretability. This project bridges that gap by:

1. **Classification**: Using deep learning (ResNet-50) to classify CT images
2. **Visual Explanation**: Generating Grad-CAM heatmaps to show WHERE the model is looking
3. **Textual Explanation**: Using RAG to explain WHY those regions are significant

---

## ğŸ“ Project Structure

```
Major Project/
â”‚
â”œâ”€â”€ main.py                 # Main entry point
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md              # This file
â”‚
â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/              # Data handling
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py     # Custom PyTorch Dataset
â”‚   â”‚   â”œâ”€â”€ transforms.py  # Image augmentation
â”‚   â”‚   â””â”€â”€ dataloader.py  # DataLoader utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ models/            # Neural network models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ classifier.py  # Main classification model
â”‚   â”‚   â””â”€â”€ model_factory.py
â”‚   â”‚
â”‚   â”œâ”€â”€ xai/               # Explainable AI
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ gradcam.py     # Grad-CAM implementation
â”‚   â”‚   â””â”€â”€ visualize.py   # Visualization utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/               # RAG Pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ knowledge_base.py      # Medical knowledge store
â”‚   â”‚   â”œâ”€â”€ xai_to_text.py         # XAI â†’ Text conversion
â”‚   â”‚   â””â”€â”€ explanation_generator.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/             # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py      # Centralized configuration
â”‚       â”œâ”€â”€ helpers.py     # Helper functions
â”‚       â””â”€â”€ metrics.py     # Evaluation metrics
â”‚
â”œâ”€â”€ notebooks/             # Jupyter notebooks for experiments
â”‚
â”œâ”€â”€ dataset/               # Dataset directory (not in repo)
â”‚   â”œâ”€â”€ adenocarcinoma/
â”‚   â”œâ”€â”€ squamous_cell_carcinoma/
â”‚   â”œâ”€â”€ large_cell_carcinoma/
â”‚   â””â”€â”€ normal/
â”‚
â”œâ”€â”€ checkpoints/           # Saved model checkpoints
â”‚
â””â”€â”€ results/               # Output results and visualizations
```

### Why This Structure?

| Directory | Purpose | Academic Justification |
|-----------|---------|----------------------|
| `src/data/` | Data loading & preprocessing | Separates data concerns from model logic |
| `src/models/` | Neural network architectures | Allows easy model comparison |
| `src/xai/` | Explainability methods | Isolates XAI implementation for clarity |
| `src/rag/` | Knowledge retrieval | Novel contribution - bridges XAI to explanations |
| `src/utils/` | Common utilities | Reduces code duplication |
| `notebooks/` | Experiments | Interactive development and visualization |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INPUT: CT SCAN IMAGE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PREPROCESSING (224x224, Normalize)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RESNET-50 (Pretrained, Fine-tuned)                â”‚
â”‚                                                                       â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚    â”‚   Features   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  Prediction  â”‚        â”‚
â”‚    â”‚   (layer4)   â”‚                          â”‚   (4 class)  â”‚        â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚           â”‚                                         â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                         â”‚
            â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      GRAD-CAM        â”‚                    â”‚  CLASS PREDICTION    â”‚
â”‚    (Visual XAI)      â”‚                    â”‚  + Confidence Score  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                         â”‚
            â–¼                                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚  XAI â†’ TEXT BRIDGE   â”‚                              â”‚
â”‚  "peripheral opacity"â”‚                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
            â”‚                                         â”‚
            â–¼                                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚  KNOWLEDGE RETRIEVAL â”‚                              â”‚
â”‚   (Medical Facts)    â”‚                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
            â”‚                                         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FINAL OUTPUT                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Prediction  â”‚  â”‚  Grad-CAM   â”‚  â”‚      RAG Explanation        â”‚  â”‚
â”‚  â”‚Adenocarcinomaâ”‚  â”‚  Heatmap    â”‚  â”‚ "Ground-glass opacity..."  â”‚  â”‚
â”‚  â”‚   (92%)     â”‚  â”‚             â”‚  â”‚                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Installation

```bash
# Clone the repository
git clone <repository-url>
cd "Major Project"

# Create virtual environment (recommended)
python -m venv venv
venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ“Š Dataset

**Source**: Kaggle - CT Scan Images of Lung Cancer Patients

**Structure**: Place the dataset in the `dataset/` folder with the following structure:
```
dataset/
â”œâ”€â”€ adenocarcinoma/
â”œâ”€â”€ squamous_cell_carcinoma/
â”œâ”€â”€ large_cell_carcinoma/
â””â”€â”€ normal/
```

**Download**: [Kaggle Dataset Link](https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images)

---

## ğŸ® Usage

```bash
# Train the model
python main.py --mode train --epochs 10

# Evaluate on test set
python main.py --mode evaluate --checkpoint checkpoints/best_model.pth

# Predict single image
python main.py --mode predict --image path/to/ct_scan.png

# Run demo pipeline
python main.py --mode demo
```

---

## ğŸ“ˆ Results

*To be updated after training*

| Metric | Value |
|--------|-------|
| Accuracy | - |
| Precision | - |
| Recall | - |
| F1 Score | - |

---

## âš ï¸ Limitations

1. **Dataset Size**: Limited medical imaging data may affect generalization
2. **Grad-CAM**: Shows correlation, not causation; may highlight spurious features
3. **RAG Simplicity**: Keyword matching is basic; doesn't capture semantic meaning
4. **Clinical Validation**: Not validated by medical professionals

---

## ğŸ”® Future Enhancements

1. **Semantic RAG**: Upgrade to sentence transformers for better retrieval
2. **Multiple XAI Methods**: Add LIME, SHAP for comparison
3. **Larger Dataset**: Include more diverse CT scan sources
4. **Clinical Validation**: Partner with radiologists for validation
5. **Web Interface**: Build a user-friendly web application

---

## ğŸ“š References

1. Selvaraju, R. R., et al. (2017). "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization." ICCV 2017.
2. He, K., et al. (2016). "Deep Residual Learning for Image Recognition." CVPR 2016.
3. Lewis, P., et al. (2020). "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks." NeurIPS 2020.

---

## ğŸ‘¥ Authors

Major Project Team - Final Year B.Tech

---

## ğŸ“„ License

This project is for academic purposes only.
